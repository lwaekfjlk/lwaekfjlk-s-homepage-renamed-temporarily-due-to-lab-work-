---
title: "Attention is All You Need"
author_profile: true
date: 2019-10-20
tags: [Transformer]
mathjax: "true"
header:
    image: "/imgs/blog4.png"
excerpt: "Transformer"
---

## 本文探讨的主题：Transformer模型

## 本文想要解决的问题： 如何通过对RNN和CNN结构的暴力抛弃，通过全新思路提高并行计算性能 

## Transformer的主要思想

Transformer之所以非常重要在于他抛弃了RNN和CNN的结构，整个网络结构完全是由Attention机制组成。

Transformer的出现解决了两个问题：
1）RNN中时刻T的结果依赖于时(T-1)的结果，从设计思想上就限制了RNN的计算并行性。目前对RNN性能工作的提升主要集中在条件计算和分解技巧，对本质的这个时刻顺序性结构没有方法进行并行优化。Transformer模型做到了序列的并行优化。

2）想RNN，CNN等顺序计算的过程中信息会丢失，尽管LSTM使用遗忘门等门结构机制在一定程度上缓解了信息消失的问题，但是在特别长的序列处理中也没有很大的作用。Transformer模型做到了模型依赖现象与输入输出无关。

##Transformer模型框架

层层解析Transformer细节：

**STEP 1）**

​	 把Transformer看作一个黑箱，input的是德语，output的是英语。

​	 Transformer模型中，input的词向量维度是512维。

**STEP 2）**

​	 把黑箱拆开，发现本质上Transformer是input->Encoder->Decoder->Output的结构，大多数最先进的神经网络序列化传导模型都有Encoder和Decoder的结构，这种思路并没有什么特别的。

**STEP 3）**

​	 把Encoder拆开发现有6个Sub-Encoder，把Decoder拆开发现有6个Sub-Decoder，每个sub部分都是相同的。

**STEP 4）**

​	 把Sub-Encoder拆开来看，有俩东西**Self-Attention**->**Feed Forward Neural Network**。

​	 把Sub-Decoder拆开来看，有仨东西**Self-Attention**->**Encoder-Decoder Attention**->**Feed Forward Neural Network**。 

   Self-Attention 层代表当前翻译和已经翻译的前文之间的关系

   Encoder-Decoder Attention 层代表当前翻译和编码的特征向量之间的关系

**STEP 5）**

​	 每个Sub-Encoder内的两个layer之间用**残差连接+正规化**连接，数学一点写，每个Sub-Encoder的output是**LayerNorm(x+Sublayer(x))**。Sub-Decoder的层间连接和Sub-Encoder是一样的。（目的当然是解决层数过深导致的问题啦）

**STEP 6）**

​	 把Self-Attention（Multi-Head Attention）层拆开来看看，发现里面除了一些奇奇怪怪的东西最重要的是一个**Scaled Dot-Product Attention**部件。说白了，Multi-Head Attention就是h个Scaled Dot-product Attention的集成。

​	 把Scaled Dot-product Attention拆开仔细研究：

​	 我们仔细想一想，Attention机制在Scaled Dot-product Attention的具体运算还有为啥这个方法能叫做Dot-product。

​	 经过思考，我们可以给出答案。

​	 a）说白了，Self-Attention核心单词是为每个词向量学习一个**权重**。先得记住这一点。

​	 b）那么我们Self-Attention的input从哪来呢？学习权重，输入的是词向量这个事情就不太合适，所以**用**$W_Q,W_K,W_v$**三个超参矩阵将词向量变成三个向量Query，Key，Value。**

​    c）有了三个向量作为input，我们可以进行Scaled Dot-product Attention的运算了。先算出一个$score=q\cdot k$,再归一化，再softmax得到一个数，再把这个数和value做dot-procut得出Z。

​		 简单来说，attention主要做的就是两次dot-product。把三个向量变成了一个值，这个值就是每个词向量的权重。（scaled思想也包含在了三那个向量变成一个值内部）

​	d）把这个公式压缩到数学公式里面，得到$Attention(Q,K,V) = softmax(\frac{QK^{T}}{\sqrt{d_k}})V$ 。一个简单的公式就把整个Scaled Dot-product Attention讲清楚了。

**STEP 7）**

​	 明白了最关键的组件，再回过头来看Multi-Head Attention，就会比较清晰。

​	 说白了，Multi-Head Attention就是有很多组并行输入，最后得到好多个Z向量，在通过一个全连接层就可以输出一个最终的Z。**（Scaled Dot-Product Attention的并行化+ 全连接）**

**STEP 8）**

​	  剩下的部分已经不多了，核心内容已经解决，还有一些边缘性的分类需要处理。

​      Attention机制在Transformer模型中有三种形式，他们仅仅是输入输出的来源不同

​      1）**encoder-decoder attention layer**。在这个结构中和**Q**来自前一个解码器的输出，**K**和**V**来自编码器的输出，其他完全相同。这让decoder每个部分都能接收到输入序列的每个部分。

​     2）**Self-attention layer in encoder**。在这个结构中**K，Q，V**都来自于编码器。编码器的每个位置都能接收到之前编码器的信息。

​	3）**Self-attention layer in decoder**。在这个结构中**K，Q，V**都来自于解码器。解码器的每个位置都能接收到之前解码器的信息。为了防止编码器信息的汇入和为了保持自动回归性质，我们在scaled dot-product attention中添加了mask（**遮挡**）层，文中叫做masked multi-head attention。

**STEP 9）**

​    还有一个部分就是Feed Forward，就是正常的神经网络**全连接结构**。

​	还有一个部分就是Positional Encoding。没recurrent，没convolution，为了添加序列信息，得给整个input加入一些位置信息。这个想法非常自然，因为处理的是序列，没有序列信息咋行。



## Self-Attention的优越性

* 并行计算部分多
* 每层计算复杂度低
* 长序列依赖性强
* 有适用于不同形态数据的可能和利用本地限制性注意力机制处理大规模数据（视频，音频）的可能





​			

​			





